<!DOCTYPE html>
<html lang="en">
  <head>

    <!-- Add auto ads -->
     <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4883532934102393"
     crossorigin="anonymous"></script>
     
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>IGTechTeam</title>

    <!-- Favicon -->
    <link
      rel="icon"
      type="image/png"
      href="/static/images/favicon.png"
    />

    <!-- Bootstrap CSS -->
    <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    />

    <!-- TinyMCE CDN (v8, with API key) -->
    <script src="https://cdn.tiny.cloud/1/cu5386mwdbw5uvluas7htq32hn0uibngcmaylurs3dl7xhc9/tinymce/8/tinymce.min.js" referrerpolicy="origin" crossorigin="anonymous"></script>

    <!-- Highlight.js -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/github-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>

    <!-- Font Awesome CDN -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css"
    />
    <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@700&display=swap" rel="stylesheet">


    <!-- jQuery (required for Bootstrap, not TinyMCE) -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>

    <!-- Bootstrap JS (for navbar toggle) -->
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>

    <link rel="stylesheet" href="/static/css/style.css">
  </head>
  <body>
    <!-- Navbar -->
    <nav class="navbar navbar-expand-lg navbar-dark sticky-top glass-nav">
      <div class="container d-flex align-items-center justify-content-between">
        <!-- Left: Logo -->
        <a class="navbar-brand fw-bold fs-3" href="/">
          IGTechTeam
        </a>

        <!-- Center: Nav links -->
        <div class="collapse navbar-collapse justify-content-center" id="navbarContent">
          <ul class="navbar-nav align-items-center">
            
            <li class="nav-item mx-2">
              <a class="nav-link fw-semibold" href="/contact.html">Contact</a>
            </li>
            <li class="nav-item mx-2">
              <a class="nav-link fw-semibold" href="/about.html">About Me</a>
            </li>
            <!-- Play Game separated with margin -->
            <li class="nav-item mx-4 ms-5">
              <a class="nav-link fw-bold play-game-link" href="/game.html">Play Game</a>
            </li>
          </ul>
        </div>

        <!-- Right: Login/Logout buttons -->
        <div class="d-flex align-items-center gap-2">
          
          <a href="/login.html" class="btn btn-success btn-sm px-4 py-2 fw-semibold shadow-sm">
            <i class="bi bi-box-arrow-in-right me-1"></i> Login
          </a>
          
        </div>

        <!-- Toggler button for small screens -->
        <button
          class="navbar-toggler ms-3"
          type="button"
          data-bs-toggle="collapse"
          data-bs-target="#navbarContent"
          aria-controls="navbarContent"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
      </div>
    </nav>

    <!-- Site Notice -->
    
    


    <!-- Flash Messages -->
    <div class="container">
      
    </div>

    <!-- Page Content -->
    <div class="container page-content">

<!-- Post Header -->
<header
  class="post-header"
  style="
    background: linear-gradient(135deg, #1d2b64, #f8cdda);
    color: white;
    padding: 2.5rem;
    border-radius: 16px 16px 0 0;
    box-shadow: 0 6px 15px rgba(0, 0, 0, 0.1);
    text-align: center;
  "
>
  <h1
    style="
      font-size: 2.8rem;
      font-weight: bold;
      color: white;
      -webkit-text-stroke: 1px black;
      text-shadow: 2px 2px 6px rgba(0, 0, 0, 0.5);
      letter-spacing: 1px;
      text-align: center;
      margin-bottom: 1rem;
    "
  >
    Generative AI ‚Äî Complete, simple, step-by-step guide (for beginners)
  </h1>

  <span
    style="
      background: rgba(255, 255, 255, 0.2);
      padding: 0.4rem 1rem;
      border-radius: 20px;
      font-size: 0.95rem;
    "
  >
    üïí 2025-11-23 11:59:36.234654
  </span>
</header>

<!-- Post Body -->
<div
  class="post-content"
  style="
    padding: 2rem;
    background: #ffffff;
    border-radius: 0 0 16px 16px;
    box-shadow: 0 6px 20px rgba(0, 0, 0, 0.05);
    margin-top: -1px;
  "
>
  <div class="post-body"><h1><img style="width: 640px;" src="https://drive.google.com/thumbnail?id=1fdxVQdeVUAWvL7qoHusnzgV7ORKqd5bu&amp;sz=w1000" data-filename="artificial-intelligence-6767502_640.jpg"></h1>
<h1>Generative AI - ALL IN ONE</h1>
<h2>1. What is Generative AI (Gen AI)?</h2>
<p>Generative AI is a type of artificial intelligence that creates new content.&nbsp;<span style="font-size: 1rem;">Instead of only analyzing data, it can produce text, images, audio, code, or even videos.&nbsp;</span><span style="font-size: 1rem;">The most powerful form of Generative AI today is the Large Language Model (LLM).&nbsp;</span><span style="font-size: 1rem;">An LLM is trained on massive amounts of text from books, websites, and code. Because of this training, it can:</span></p>
<ul>
<li><span style="font-size: 1rem;">understand human language,</span></li>
<li>answer questions,</li>
<li>write stories or articles,</li>
<li>solve coding tasks,</li>
<li>summarise information,</li>
<li>chat like a human.</li>
</ul>
<p><strong>Why Generative AI Matters</strong></p>
<p>Generative AI is important because it allows people to build powerful tools such as:</p>
<ul>
<li><strong>Chatbots</strong>: Customer support, personal assistants</li>
<li><strong>Writing helpers</strong>: Blog writers, email writers, grammar fixers</li>
<li><strong>Code assistants</strong>: Debugging, writing functions, explaining errors</li>
<li><strong>Content creation tools</strong>: Images, videos, music, designs</li>
</ul>
<p>It saves time, reduces effort, and improves productivity.</p>
<p><strong>But It Has Limitations (Hallucinations)</strong></p>
<p>Sometimes, Generative AI gives confident but incorrect answers.&nbsp;<span style="font-size: 1rem;">This is called a hallucination.</span></p>
<p><strong>Example:</strong></p>
<p>If the model does not know something exactly, it may guess or create a wrong answer.</p>
<p><span style="font-size: 1rem;">We will later learn ways to reduce hallucinations using:</span></p>
<ul>
<li><span style="font-size: 1rem;">Prompt engineering</span></li>
<li>Retrieval-Augmented Generation (RAG)</li>
<li>Using external tools and APIs</li>
<li>Better model instructions</li>
</ul>
<p>&nbsp;</p>
<h2>2. Key building blocks</h2>
<p><strong>a. LLM (Large Language Model)</strong></p>
<p>The core engine that writes, answers, explains, and reasons.<br>Examples: GPT, Claude, Llama.<br>You send text &rarr; it gives a response.</p>
<p>&nbsp;</p>
<p><strong>b. Prompt</strong></p>
<p>A message or instruction you give to the model.<br>It tells the AI what you want.<br>Example: &ldquo;Write a short email to my boss.&rdquo;</p>
<p>&nbsp;</p>
<p><strong>c. Prompt Engineering</strong></p>
<p>The skill of designing better prompts so the AI gives accurate, useful answers.<br>This includes adding examples, structure, or clear instructions.</p>
<p>&nbsp;</p>
<p><strong>d. Embeddings</strong></p>
<p>A way to turn text into numbers (vectors) so that computers can understand meaning.<br>If two texts are similar, their embeddings will also be similar.<br>Used for search, clustering, similarity checks, etc.</p>
<p>&nbsp;</p>
<p><strong>e. Vector Store</strong></p>
<p>A special database that stores embeddings.<br>It lets you quickly search for similar text.<br>Popular options: FAISS, Chroma, Pinecone, Weaviate.</p>
<p>&nbsp;</p>
<p><strong>f. RAG (Retrieval-Augmented Generation)</strong></p>
<p>A technique where you:</p>
<ul>
<li>Search your knowledge base using embeddings.</li>
<li>Retrieve useful documents.</li>
<li>Pass them to the LLM to get a correct answer.</li>
</ul>
<p>This makes answers more accurate and reduces hallucinations.</p>
<p>&nbsp;</p>
<p><strong>g. LangChain</strong></p>
<p>A Python/JavaScript library that helps you build AI apps.<br>It provides:</p>
<ul>
<li>Chains (multi-step logic)</li>
<li>RAG pipelines</li>
<li>Memory</li>
<li>Tool calling</li>
<li>Integrations with models and vector stores</li>
</ul>
<p>It's like a framework for building LLM applications quickly.</p>
<h5>&nbsp;</h5>
<p><strong>h. Agents &amp; Tools</strong></p>
<p>Agents let the model call functions or APIs automatically.<br>Example:</p>
<ul>
<li>AI checks weather by calling a weather API</li>
<li>AI fetches data from a database</li>
<li>AI runs Python code</li>
</ul>
<p>This makes models act more like smart assistants.</p>
<p>&nbsp;</p>
<p><strong>i. MCP Server (Model Context Protocol / Model Control Plane)</strong></p>
<p>A standard that lets AI models securely access external tools, databases, and services.<br>It works like a bridge between the model and your system.<br>For example, with MCP:</p>
<ul>
<li>AI can fetch data from your database</li>
<li>AI can read files or run local tools</li>
<li>AI can call APIs using a controlled and safe method</li>
</ul>
<p>Modern tools like OpenAI&rsquo;s GPTs use MCP directly.</p>
<p>&nbsp;</p>
<h2>3.&nbsp;Prompts: how to speak to the model</h2>
<p>A prompt is just text. Clear, simple prompts give better results.</p>
<p><strong>Good prompt tips:</strong></p>
<ul>
<li>Be specific. Don&rsquo;t assume the model knows context.</li>
<li>Show examples (few-shot) for pattern learning.</li>
<li>Give format instructions (e.g., &ldquo;Return JSON with fields: title, summary&rdquo;).</li>
<li>Limit creativity if you need facts: add &ldquo;Be concise and factual.&rdquo;</li>
</ul>
<p><strong>Example: Simple prompt</strong></p>
<div>
<pre class="language-python"><code>You are a helpful assistant.
Task: Summarize the text below in one sentence.

Text: "LangChain helps developers build apps that combine LLMs with external tools."

Answer:</code></pre>
</div>
<p><strong>Prompt + instruction + constraints (stronger)</strong></p>
<pre class="language-python"><code>You are a helpful assistant. Return only JSON.

Task: From the text, return {"summary": "...", "keywords": ["a","b"]}

Text: "LangChain helps developers build apps that combine LLMs with external tools."</code></pre>
<pre>&nbsp;</pre>
<h2>4.&nbsp;Basic code: calling an LLM (Python, OpenAI style)</h2>
<p>(Install <span style="background-color: #cedee7;">openai</span> or use your provider's SDK and set <span style="background-color: #cedee7;">OPENAI_API_KEY</span>)</p>
<pre class="language-python"><code># pip install openai
import os
import openai

openai.api_key = os.getenv("OPENAI_API_KEY")

def ask(prompt):
    resp = openai.ChatCompletion.create(
        model="gpt-4o-mini",  # example model name
        messages=[{"role":"user","content": prompt}],
        max_tokens=200
    )
    return resp["choices"][0]["message"]["content"]

print(ask("Write a 2-line summary of 'RAG' in simple words."))</code></pre>
<p>Replace model name with whatever your provider offers. Keep tokens and costs in mind.</p>
<p>&nbsp;</p>
<h2>5. Embeddings: turning text into numbers (for search)</h2>
<p>Embeddings let you compare meaning. Steps:</p>
<ol>
<li>Break text into chunks.</li>
<li>Call embedding model on each chunk.</li>
<li>Store vectors in a vector store.</li>
<li>For a user query, embed it, then find nearest vectors.</li>
</ol>
<p>Example using OpenAI embeddings (conceptual)</p>
<pre class="language-python"><code># pip install openai numpy
import openai
import numpy as np

def get_embedding(text):
    resp = openai.Embedding.create(
        model="text-embedding-3-small",
        input=text
    )
    return np.array(resp["data"][0]["embedding"])</code></pre>
<p>You usually store these vectors in FAISS, Chroma, Pinecone, etc.</p>
<p><span style="color: #000000; font-family: sans-serif; font-size: 16px; white-space: normal;">&nbsp;</span></p>
<h2>6.&nbsp;What is RAG (Retrieval-Augmented Generation)?</h2>
<p><strong>RAG </strong>= Retrieval-Augmented Generation.</p>
<p><strong>Idea</strong>: before asking the model to answer, fetch relevant documents (from your files, manuals, website) and give those to the model as context. This reduces hallucinations and lets the model use up-to-date or private data. Many cloud providers and docs explain this pattern.&nbsp;</p>
<p><strong>Simple RAG flow: </strong></p>
<ol>
<li>Ingest docs &rarr; split into chunks &rarr; embed &rarr; store.</li>
<li>On user question: embed query &rarr; retrieve top-k chunks.</li>
<li>Build a prompt with those chunks and the question &rarr; send to LLM.</li>
<li>Return answer (optionally include sources).</li>
</ol>
<p>&nbsp;</p>
<h2>7.&nbsp;LangChain: glue to build LLM apps</h2>
<p>LangChain is a popular library that helps build chains, agents, RAG pipelines, and connects LLMs to tools. It has loaders for documents, wrappers for models, and helpers for vector stores. Use it when you want a structured app instead of raw API calls.&nbsp;</p>
<p><strong>Short LangChain RAG example (Python)</strong></p>
<pre class="language-python"><code> # pip install langchain openai chroma-client
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 1. load docs
loader = TextLoader("docs/manual.txt", encoding="utf-8")
docs = loader.load()

# 2. split
splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
chunks = splitter.split_documents(docs)

# 3. embeddings + vector store
emb = OpenAIEmbeddings()
vectordb = Chroma.from_documents(chunks, emb, collection_name="manuals")

# 4. create retriever and QA chain
retriever = vectordb.as_retriever(search_kwargs={"k": 4})
llm = ChatOpenAI(temperature=0, model_name="gpt-4o-mini")
qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever)

# 5. ask
print(qa.run("How do I reset the device?")
</code></pre>
<pre><strong>Notes:</strong></pre>
<ul>
<li><span style="background-color: #cee7f7;">chain_type="stuff"</span> is one way (puts all contexts into prompt). There are other chain types (map-reduce, refine) for long contexts.</li>
<li>Replace Chroma with FAISS, Pinecone, etc., as needed.</li>
</ul>
<p>&nbsp;</p>
<h2>8.&nbsp;Vector stores quick guide</h2>
<p>Common vector stores:</p>
<ul>
<li><strong>FAISS </strong>&mdash; offline, local, fast (Facebook/Meta).</li>
<li><strong>Chroma </strong>&mdash; simple local store with helpful features.</li>
<li><strong>Pinecone / Weaviate / Milvus</strong> &mdash; hosted and scalable.</li>
</ul>
<p>Pick local FAISS for prototypes, hosted for production.</p>
<p>&nbsp;</p>
<h2>9.&nbsp;Agents and tools (models calling actions)</h2>
<p>Agents let models call tools (like calculators, search, or your APIs). This is powerful: model decides which tool to use. But it needs careful guardrails.</p>
<p><strong>LangChain Agents example</strong></p>
<pre class="language-python"><code>from langchain.agents import initialize_agent, Tool
from langchain.tools import BaseTool
from langchain.llms import OpenAI

def search_web(query):
    # your search code here
    return "search results for: " + query

tools = [Tool(name="web_search", func=search_web, description="Search the web")]

llm = OpenAI(temperature=0)
agent = initialize_agent(tools, llm, agent="zero-shot-react-description")
print(agent.run("Find latest release of Python and summarize."))</code></pre>
<p>Agents + MCP (next section) is how models call real system tools securely.<br><br></p>
<h2>10.&nbsp;MCP servers: what and why</h2>
<p><strong>MCP</strong> stands for Model Context Protocol (often called Model Context Protocol or Model Control Plane in different contexts). It is an open protocol and ecosystem that standardizes how LLMs (or hosts) connect to external tools, data, and services via a client-server style interface. An MCP server exposes tool endpoints and data to the model in a standardized way so many models and tools can interoperate. This makes building connected AI easier and reduces custom glue code.</p>
<p><strong>Key points:</strong></p>
<ul>
<li><span style="font-size: 1rem;">MCP servers provide a JSON-RPC API or similar interface models can call.</span></li>
<li>They expose tools with schema (what inputs they need, what they return).</li>
<li>MCP reduces the N&times;M problem: many models &times; many tools.</li>
</ul>
<p><em>Security note</em>: MCP servers have high privileges and can access sensitive data. There have been real security incidents where a malicious MCP server exfiltrated email data. Always verify MCP server code and use least-privilege access.</p>
<p>&nbsp;</p>
<h2>11.&nbsp;Example: simple MCP-like tool (conceptual)</h2>
<p>This is a toy HTTP server that exposes a tool "get_time". Real MCP is a spec; production MCP servers follow the protocol</p>
<pre class="language-python"><code># Very simple Flask server exposing a tool
# pip install flask
from flask import Flask, request, jsonify
import datetime

app = Flask(__name__)

@app.route("/tool/get_time", methods=["POST"])
def get_time():
    payload = request.json or {}
    tz = payload.get("tz", "UTC")
    now = datetime.datetime.utcnow().isoformat() + "Z"
    return jsonify({"result": f"Current time (UTC): {now}"})
LLM (Large Language Model)
if __name__ == "__main__":
    app.run(port=8080)</code></pre>
<p>In real MCP, the model or client would call a standard RPC endpoint and the server would return structured data. Use authentication, logging, and permission checks.<br><br></p>
<h2>12.&nbsp;Reducing hallucination &amp; improving reliability</h2>
<p><strong>Common techniques:</strong></p>
<ul>
<li><strong>Use RAG</strong>: give the model real documents to base answers on.</li>
<li><span style="font-size: 1rem;"><strong>Provide system instructions</strong> (role + constraints).</span></li>
<li><strong>Chain-of-thought control</strong>: prefer concise reasoning, avoid verbose internal chains when you want short answers.</li>
<li><strong>Verify</strong>: ask the model to cite sources. Build a check that compares returned facts with the source texts.</li>
<li><strong>Limit model temperature</strong> (0&ndash;0.3) for factual answers.</li>
<li><strong>Human-in-the-loop</strong>: for critical outputs, require human review.</li>
</ul>
<p>&nbsp;</p>
<h2>13.&nbsp;Evaluation &amp; testing</h2>
<p>Always measure:</p>
<ul>
<li><strong>Accuracy </strong>(is the answer correct?)</li>
<li><strong>Recall </strong>(does it find needed info?)</li>
<li><strong>Latency </strong>(how fast?)</li>
<li><strong>Cost </strong>(API tokens, compute)</li>
<li><strong>Safety </strong>(PII leakage, prompt injection)</li>
</ul>
<p>Unit test flows: write test cases (question &rarr; expected answer or expected doc id). Use LangChain/LangSmith or your own logging to trace failures.</p>
<p>&nbsp;</p>
<h2>14.&nbsp;Deployment tips</h2>
<ul>
<li>Use separate environments (dev/staging/prod).</li>
<li>Cache embeddings and vector stores; recompute only when content changes.</li>
<li>Protect API keys and use quotas.</li>
<li>Use least-privilege for MCP servers; run them in trusted networks.\</li>
<li>Monitor input/output for data exfiltration (especially with MCP/tool calls).</li>
<li>Consider model fallback strategies (e.g., use smaller cheaper model for trivial tasks; bigger model for hard tasks).</li>
</ul>
<p>&nbsp;</p>
<h2>15.&nbsp;Simple end-to-end mini project (RAG Q&amp;A)</h2>
<p><strong>Steps:</strong></p>
<ol>
<li>Gather docs (PDFs, web pages).</li>
<li>Convert to text, split into chunks (500&ndash;1000 chars).</li>
<li>Create embeddings for each chunk.</li>
<li>Store in vector DB (Chroma / FAISS / Pinecone).</li>
<li>Build retriever (top k).</li>
<li>Create prompt template: include top chunks and user question.</li>
<li>Call LLM to generate answer with sources.</li>
</ol>
<p>We showed code with LangChain earlier &mdash; that&rsquo;s a complete minimal RAG.</p>
<p>&nbsp;</p>
<h2>16.&nbsp;Short glossary (simple)</h2>
<ul>
<li><strong>Hallucination</strong>: model says something wrong as if it were true.</li>
<li><strong>Embedding</strong>: vector representing meaning.</li>
<li><strong>Retriever</strong>: component that finds relevant text from a vector store.</li>
<li><strong>Vector store</strong>: database for embeddings.</li>
<li><strong>Prompt engineering</strong>: designing instructions for models.</li>
<li><strong>Agent</strong>: model plus tools that can act.</li>
<li><strong>MCP server</strong>: standardized server exposing tools/data to models.</li>
</ul>
<p>&nbsp;</p>
<h3><strong>WANT TO MAKE A COMPLETE PROJECT:</strong></h3>
<p>Here is the link:</p>
<p><span style="font-size: 1rem;"><strong>AI Debate Bot:&nbsp;</strong></span></p>
<ul>
<li>YouTube:&nbsp;<a href="https://youtu.be/WF2X6tYo3kY" target="_blank" rel="noopener">https://youtu.be/WF2X6tYo3kY</a></li>
<li>Github:&nbsp;<a href="https://github.com/IshwarGautam/Gen-AI-debate-" target="_blank" rel="noopener">https://github.com/IshwarGautam/Gen-AI-debate-</a></li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;</p></div>

<script>
  if (window.hljs) {
    hljs.highlightAll();
  }
</script>
</div>

<!-- Comment section -->
<div class="comments-wrapper">
  <h4>Leave a Comment</h4>
  <form method="POST" class="p-3 bg-light rounded shadow">
    <input type="hidden" name="parent_id" value="" />

    <div class="form-group">
      <label>Your Name</label>
      <input type="text" name="name" class="form-control" required />
    </div>

    <div class="form-group">
      <label>Your Comment</label>
      <textarea name="content" class="form-control" rows="3" required></textarea>
    </div>

    <button type="submit" class="btn btn-primary">Post Comment</button>
  </form>
</div>
<hr />



        <style>
        .comment-container {
            margin-left: 20px;
            margin-bottom: 1rem;
            padding: 1rem;
            border: 1px solid #ddd;
            border-radius: 8px;
            background: #fafafa;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }

        .comment-header {
            font-weight: 600;
            font-size: 0.95rem;
            color: #333;
            margin-bottom: 0.3rem;
        }

        .comment-timestamp {
            font-weight: 400;
            font-size: 0.8rem;
            color: #777;
            margin-left: 0.5rem;
        }

        .comment-content {
            margin-bottom: 0.8rem;
            white-space: pre-wrap;
        }

        .reply-link {
            font-size: 0.85rem;
            color: #1877f2;
            cursor: pointer;
            user-select: none;
        }

        .reply-link:hover {
            text-decoration: underline;
        }

        .reply-form {
            margin-top: 0.8rem;
            display: none;
        }

        .reply-form input,
        .reply-form textarea {
            font-size: 0.9rem;
            margin-bottom: 0.5rem;
        }

        .reply-form button {
            font-size: 0.85rem;
        }

        /* Nested replies indent */
        .nested-replies {
            margin-left: 30px;
            margin-top: 1rem;
        }

        .comments-wrapper {
            margin: 20px auto;
            padding: 15px 20px;
            background-color: #f9f9f9;
            border-radius: 8px;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
            font-family: Arial, sans-serif;
        }

        .comments-wrapper h4 {
            margin-bottom: 15px;
            color: #333;
            font-weight: 600;
            font-size: 1.5rem;
            border-bottom: 2px solid #4CAF50;
            padding-bottom: 5px;
        }
        </style>

      <div class="comments-wrapper">
        <h4>Comments</h4>
        <div class="comment-container">
            <p>Loading comments...</p>
        </div>
        </div>

        <script>
        (function () {
          const form = document.querySelector("form");
          const commentsContainer = document.querySelector(".comment-container");
          if (!form || !commentsContainer) return;

          const slug = "generative-ai-complete-simple-step-by-step-guide-for-beginners";
          const submitBtn = form.querySelector("button[type='submit']");

          form.addEventListener("submit", function (e) {
            e.preventDefault();
            const data = {
              slug,
              name: form.name.value.trim(),
              content: form.content.value.trim(),
              parent_id: form.parent_id.value || null,
            };

            if (!data.name || !data.content) {
              alert("Please fill in your name and comment.");
              return;
            }

            const originalText = submitBtn.textContent;
            submitBtn.disabled = true;
            submitBtn.textContent = "Posting...";

            fetch("/.netlify/functions/submit_comment", {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
              },
              body: JSON.stringify(data),
            })
            .then(res => {
              submitBtn.disabled = false;
              submitBtn.textContent = originalText;
              if (res.ok) {
                alert("Comment submitted!");
                form.reset();
                loadComments();
              } else {
                return res.text().then(text => alert("Failed: " + text));
              }
            })
            .catch(err => {
              submitBtn.disabled = false;
              submitBtn.textContent = originalText;
              alert("Error: " + err.message);
            });
          });

          function loadComments() {
            fetch(`/.netlify/functions/get_comments?slug=${encodeURIComponent(slug)}`)
              .then(res => {
                if (!res.ok) throw new Error("Failed to load comments");
                return res.json();
              })
              .then(comments => {
                commentsContainer.innerHTML = "";
                const map = {};
                comments.forEach(c => {
                  c.children = [];
                  map[c.id] = c;
                });
                comments.forEach(c => {
                  if (c.parent_id && map[c.parent_id]) {
                    map[c.parent_id].children.push(c);
                  }
                });

                const render = (comment) => {
                  const wrapper = document.createElement("div");
                  wrapper.className = "comment-container";

                  const header = document.createElement("div");
                  header.className = "comment-header";
                  header.innerHTML = `<strong>${escapeHtml(comment.name)}</strong><span class="comment-timestamp"> - ${new Date(comment.timestamp).toLocaleString()}</span>`;
                  wrapper.appendChild(header);

                  const content = document.createElement("div");
                  content.className = "comment-content";
                  content.textContent = comment.content;
                  wrapper.appendChild(content);

                  const replyLink = document.createElement("span");
                  replyLink.className = "reply-link";
                  replyLink.textContent = "Reply";
                  replyLink.onclick = () => toggleReplyForm(`reply-form-${comment.id}`);
                  wrapper.appendChild(replyLink);

                  const replyForm = document.createElement("form");
                  replyForm.method = "POST";
                  replyForm.className = "reply-form";
                  replyForm.id = `reply-form-${comment.id}`;
                  replyForm.innerHTML = `
                    <input type="hidden" name="parent_id" value="${comment.id}" />
                    <input type="text" name="name" placeholder="Your Name" class="form-control form-control-sm" required />
                    <textarea name="content" placeholder="Write a reply..." class="form-control form-control-sm" rows="2" required></textarea>
                    <button type="submit" class="btn btn-sm btn-primary">Post Reply</button>
                  `;
                  replyForm.addEventListener("submit", function (e) {
                    e.preventDefault();
                    const replyData = {
                      slug,
                      name: replyForm.name.value.trim(),
                      content: replyForm.content.value.trim(),
                      parent_id: comment.id,
                    };

                    if (!replyData.name || !replyData.content) {
                      alert("Please fill in your name and reply.");
                      return;
                    }

                    const replyBtn = replyForm.querySelector("button");
                    const originalText = replyBtn.textContent;
                    replyBtn.disabled = true;
                    replyBtn.textContent = "Posting...";

                    fetch("/.netlify/functions/submit_comment", {
                      method: "POST",
                      headers: {
                        "Content-Type": "application/json",
                      },
                      body: JSON.stringify(replyData),
                    })
                      .then(res => {
                        replyBtn.disabled = false;
                        replyBtn.textContent = originalText;
                        if (res.ok) {
                          alert("Reply submitted!");
                          replyForm.reset();
                          replyForm.style.display = "none";
                          loadComments();
                        } else {
                          return res.text().then(text => alert("Failed: " + text));
                        }
                      })
                      .catch(err => {
                        replyBtn.disabled = false;
                        replyBtn.textContent = originalText;
                        alert("Error: " + err.message);
                      });
                  });
                  wrapper.appendChild(replyForm);

                  if (comment.children.length) {
                    const nested = document.createElement("div");
                    nested.className = "nested-replies";
                    comment.children.forEach(child => nested.appendChild(render(child)));
                    wrapper.appendChild(nested);
                  }

                  return wrapper;
                };

                const topLevel = comments.filter(c => !c.parent_id);
                if (topLevel.length === 0) {
                  commentsContainer.innerHTML = "<p>No comments yet. Be the first to comment!</p>";
                } else {
                  topLevel.forEach(c => commentsContainer.appendChild(render(c)));
                }
              })
              .catch(err => {
                commentsContainer.innerHTML = "<p>Failed to load comments.</p>";
                console.error(err);
              });
          }

          function toggleReplyForm(id) {
            const form = document.getElementById(id);
            if (form) {
              const isHidden = window.getComputedStyle(form).display === "none";
              form.style.display = isHidden ? "block" : "none";
            }
          }

          function escapeHtml(text) {
            return text
              .replace(/&/g, "&amp;")
              .replace(/</g, "&lt;")
              .replace(/>/g, "&gt;")
              .replace(/"/g, "&quot;")
              .replace(/'/g, "&#039;");
          }

          loadComments();
        })();
        </script>
        
<!-- Post Footer -->
<footer
  class="post-footer"
  style="
    margin-top: 2rem;
    background: #f1f3f6;
    padding: 2rem;
    border-radius: 16px;
    text-align: center;
    font-size: 0.95rem;
    color: #444;
    box-shadow: 0 -4px 10px rgba(0, 0, 0, 0.05);
  "
>
  <p><strong>Author:</strong> Ishwar Gautam</p>

  <!-- Buttons -->
  <div style="margin: 1rem 0">
    <a
      href="/"
      class="btn btn-outline-primary"
      style="margin-right: 1rem"
      >‚Üê Back to Home</a
    >
    <a
      href="#"
      onclick="window.scrollTo({top: 0, behavior: 'smooth'});"
      class="btn btn-primary"
      >‚Üë Back to Top</a
    >
  </div>

  <!-- Social Icons -->
  <div class="social-icons" style="margin-top: 1.5rem">
    <a
      href="https://www.facebook.com/igtechteam/"
      target="_blank"
      style="margin: 0 10px; font-size: 1.5rem; color: #3b5998"
      ><i class="fab fa-facebook"></i
    ></a>
    <a
      href="https://www.instagram.com/ishwar_gautam1/"
      target="_blank"
      style="margin: 0 10px; font-size: 1.5rem; color: #e4405f"
      ><i class="fab fa-instagram"></i
    ></a>
    <a
      href="https://github.com/ishwargautam"
      target="_blank"
      style="margin: 0 10px; font-size: 1.5rem; color: #333"
      ><i class="fab fa-github"></i
    ></a>
    <a
      href="https://www.linkedin.com/in/ishwargautam1"
      target="_blank"
      style="margin: 0 10px; font-size: 1.5rem; color: #0077b5"
      ><i class="fab fa-linkedin"></i
    ></a>
    <a
      href="https://www.tiktok.com/@ishwar.gautam1?_t=8pdEalQ0Nn7&_r=1"
      target="_blank"
      style="margin: 0 10px; font-size: 1.5rem; color: #000"
      ><i class="fab fa-tiktok"></i
    ></a>
  </div>

  <!-- YouTube Subscribe -->
  <div style="margin-top: 1.5rem">
    <a
      class="youtube-btn"
      href="https://www.youtube.com/channel/UC4Wf9XNPsbXwQqfKlUZfmtw?sub_confirmation=1"
      target="_blank"
      style="
        background: #ff0000;
        color: white;
        padding: 0.6rem 1.2rem;
        border-radius: 30px;
        text-decoration: none;
        font-weight: bold;
        transition: background 0.3s ease;
      "
    >
      üîî Subscribe on YouTube
    </a>
  </div>
</footer>

</div>

    <!-- Footer -->
    
<!-- Leaving this empty so to skip base.html footer-->


    <!-- TinyMCE Initialization (official example, all features) -->
    <script>
      tinymce.init({
        selector: 'textarea.tinymce-editor',
        plugins: [
          // Core editing features
          'anchor', 'autolink', 'charmap', 'codesample', 'emoticons', 'link', 'lists', 'media', 'searchreplace', 'table', 'visualblocks', 'wordcount', 'fullscreen',
          // Free trial premium features (if available for your key)
          'checklist', 'mediaembed', 'casechange', 'formatpainter', 'pageembed', 'a11ychecker', 'tinymcespellchecker', 'permanentpen', 'powerpaste', 'advtable', 'advcode', 'advtemplate', 'ai', 'uploadcare', 'mentions', 'tinycomments', 'tableofcontents', 'footnotes', 'mergetags', 'autocorrect', 'typography', 'inlinecss', 'markdown', 'importword', 'exportword', 'exportpdf'
        ],
        toolbar: 'fullscreen | undo redo | blocks fontfamily fontsize | bold italic underline strikethrough | link media table mergetags | addcomment showcomments | spellcheckdialog a11ycheck typography uploadcare | align lineheight | checklist numlist bullist indent outdent | emoticons charmap | removeformat',
        tinycomments_mode: 'embedded',
        tinycomments_author: 'Author name',
        mergetags_list: [
          { value: 'First.Name', title: 'First Name' },
          { value: 'Email', title: 'Email' },
        ],
        ai_request: (request, respondWith) => respondWith.string(() => Promise.reject('See docs to implement AI Assistant')),
        uploadcare_public_key: 'd857dd4d5adbe5038f25',
        height: 300,
        menubar: true,
        branding: false,
        content_style: 'body { font-family: Segoe UI,Arial,sans-serif; font-size:14px }',
      });
    </script>
  </body>
</html>